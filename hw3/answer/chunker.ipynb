{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunker: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import *\n",
    "import os, sys, optparse, gzip, re, logging, random\n",
    "if os.getcwd().split('\\\\')[-1]==\"answer\":\n",
    "    os.chdir(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:02<00:00, 459.66it/s]\n"
     ]
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('data', 'train.txt.gz'), os.path.join('data', 'chunker'), '.tar')\n",
    "decoder_output = chunker.decode('data/input/dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 23663 tokens with 11896 phrases; found: 11672 phrases; correct: 8568.\n",
      "accuracy:  84.35%; (non-O)\n",
      "accuracy:  85.65%; precision:  73.41%; recall:  72.02%; FB1:  72.71\n",
      "             ADJP: precision:  36.49%; recall:  11.95%; FB1:  18.00  74\n",
      "             ADVP: precision:  71.36%; recall:  39.45%; FB1:  50.81  220\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
      "               NP: precision:  70.33%; recall:  76.80%; FB1:  73.42  6811\n",
      "               PP: precision:  92.40%; recall:  87.14%; FB1:  89.69  2302\n",
      "              PRT: precision:  65.00%; recall:  57.78%; FB1:  61.18  40\n",
      "             SBAR: precision:  84.62%; recall:  41.77%; FB1:  55.93  117\n",
      "               VP: precision:  63.66%; recall:  58.25%; FB1:  60.83  2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73.40644276901988, 72.02420981842637, 72.70875763747455)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunker: Baseline model\n",
    "\n",
    "We obtained a dev score of 76.5 for the baseline model. The baseline model was built by concatenating the character-level representation of the word with the word-embedding and passing this as an input to the default chunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import *\n",
    "import os, sys, optparse, gzip, re, logging, random\n",
    "if os.getcwd().split('\\\\')[-1]==\"answer\":\n",
    "    os.chdir(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the baseline solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1027/1027 [00:02<00:00, 430.53it/s]\n"
    }
   ],
   "source": [
    "baseline_chunker = LSTMTagger(os.path.join('../data', 'train.txt.gz'), os.path.join('../data', 'baseline'), '.tar')\n",
    "decoder_output = baseline_chunker.decode('../data/input/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LSTMTaggerModel(\n  (word_embeddings): Embedding(9675, 128)\n  (lstm): LSTM(428, 64)\n  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "baseline_chunker.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the baseline output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processed 23663 tokens with 11896 phrases; found: 11884 phrases; correct: 9106.\naccuracy:  86.67%; (non-O)\naccuracy:  87.67%; precision:  76.62%; recall:  76.55%; FB1:  76.59\n             ADJP: precision:  46.51%; recall:  17.70%; FB1:  25.64  86\n             ADVP: precision:  74.27%; recall:  44.97%; FB1:  56.03  241\n            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n               NP: precision:  74.32%; recall:  79.86%; FB1:  76.99  6702\n               PP: precision:  91.99%; recall:  87.55%; FB1:  89.71  2323\n              PRT: precision:  70.73%; recall:  64.44%; FB1:  67.44  41\n             SBAR: precision:  76.92%; recall:  42.19%; FB1:  54.50  130\n               VP: precision:  69.46%; recall:  71.18%; FB1:  70.31  2361\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(76.62403231235274, 76.546738399462, 76.58536585365853)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('../data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunker: Additional Improvement - 2nd option \n",
    "Made use of a second RNN taking input as the character level representation and used it's hidden layer and concatenated it with the word embeddings and passed it as an input to the chunker RNN.\n",
    "Obtained a dev score of 77.18 for 10 epochs. However at 3 epochs, the score was 78.4 and then, the model starts to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import *\n",
    "import os, sys, optparse, gzip, re, logging, random\n",
    "if os.getcwd().split('\\\\')[-1]==\"answer\":\n",
    "    os.chdir(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the improved solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 1027/1027 [00:03<00:00, 300.15it/s]\n"
    }
   ],
   "source": [
    "chunker = LSTMTagger(os.path.join('../data', 'train.txt.gz'), os.path.join('../data', 'chunker'), '.tar')\n",
    "decoder_output = chunker.decode('../data/input/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LSTMTaggerModel(\n  (word_embeddings): Embedding(9675, 128)\n  (lstm): LSTM(192, 64)\n  (lstm2): LSTM(300, 64)\n  (hidden2tag): Linear(in_features=64, out_features=22, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\n",
    "chunker.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the improved output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processed 23663 tokens with 11896 phrases; found: 12457 phrases; correct: 9399.\naccuracy:  86.49%; (non-O)\naccuracy:  87.67%; precision:  75.45%; recall:  79.01%; FB1:  77.19\n             ADJP: precision:  45.40%; recall:  32.74%; FB1:  38.05  163\n             ADVP: precision:  64.89%; recall:  52.01%; FB1:  57.74  319\n            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  3\n             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n               NP: precision:  76.22%; recall:  82.89%; FB1:  79.42  6783\n               PP: precision:  90.91%; recall:  88.04%; FB1:  89.45  2364\n              PRT: precision:  42.86%; recall:  60.00%; FB1:  50.00  63\n             SBAR: precision:  66.48%; recall:  50.21%; FB1:  57.21  179\n               VP: precision:  64.00%; recall:  71.74%; FB1:  67.65  2583\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(75.45155334350164, 79.00975117686617, 77.18966862398882)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "flat_output = [ output for sent in decoder_output for output in sent ]\n",
    "import conlleval\n",
    "true_seqs = []\n",
    "with open(os.path.join('../data','reference','dev.out')) as r:\n",
    "    for sent in conlleval.read_file(r):\n",
    "        true_seqs += sent.split()\n",
    "conlleval.evaluate(true_seqs, flat_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tried scRNN\n",
    "\n",
    "Implementation could be incorrect but it seems that the training data might not be enough as the denoiser does not struggle with common words. The results for trained model are shown below. Best results were obtained when vocabulary and training data were converted to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_rep_lower(word):\n",
    "    beg = {c:0 for c in [c for c in string.printable]}\n",
    "    inter = {c:0 for c in [c for c in string.printable]}\n",
    "    end = {c:0 for c in [c for c in string.printable]}\n",
    "    if word != '[unk]':\n",
    "        if len(word) == 1:\n",
    "            beg[word] += 1\n",
    "        elif len(word) == 2:\n",
    "            beg[word[0]] += 1\n",
    "            end[word[0]] += 1\n",
    "        else:\n",
    "            beg[word[0]] += 1\n",
    "            for c in range(1,len(word)-2):\n",
    "                inter[word[c]] += 1\n",
    "            end[word[-1]] += 1 \n",
    "    for l in 'QWERTYUIOPASDFGHJKLZXCVBNM':\n",
    "        del(beg[l])\n",
    "        del(inter[l])\n",
    "        del(end[l])\n",
    "    res = list(itertools.chain(list(beg.values()), list(inter.values()), list(end.values())))\n",
    "    return res\n",
    "\n",
    "class DenoiserModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, vocab_size):\n",
    "        torch.manual_seed(1)\n",
    "        super(DenoiserModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM((100-26)*3, hidden_dim, bidirectional=False)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        lstm_out, _ = self.lstm(sentence.view(len(sentence), 1, -1))\n",
    "        word_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        word_scores = F.log_softmax(word_space, dim=1)\n",
    "        return word_scores\n",
    "\n",
    "vocab = np.load(\"../data/vocab.npy\")\n",
    "vocablen = len(vocab)\n",
    "\n",
    "denoiser = DenoiserModel(650, vocablen).to(device)\n",
    "saved_model = torch.load(\"../data/denoiser.tar\", map_location='cpu')\n",
    "denoiser.load_state_dict(saved_model['model_state_dict'])\n",
    "\n",
    "denoiser.eval()\n",
    "\n",
    "def forward_denoiser(sentence):\n",
    "    sentence_lower = [word.lower() for word in sentence.split()]\n",
    "    inpt = torch.FloatTensor([char_rep_lower(word) for word in sentence_lower]).to(device)\n",
    "    tag_scores = denoiser(inpt).detach().cpu().numpy()\n",
    "    return vocab[np.argmax(tag_scores, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['flying' 'around' 'the' 'worked']\n['regional' 'said' 'the' 'agreement' 'class' 'for' 'in' 'to' 'supply'\n '250' 'additional' 'so-called' 'sessions' 'for' 'the' 'plans']\n"
    }
   ],
   "source": [
    "print(forward_denoiser(\"flyng arond the wrld\"))\n",
    "print(forward_denoiser(\"Rockwell sabid the agreement clals for it to supply 200 additional so-called shipsets for the planes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scRNN Denoising\n",
    "\n",
    "We made the B,I,E LSTM from the outlined implementation option 1 as a denoiser and fed the output of this model for dev.txt into the Tagger LSTM as a means to recreate decode noisy words in dev and test sets.\n",
    "\n",
    "When looking at the results of the output for the denoiser model, it appeared that the model was not working as expected and led to a decrease in F1 score. The noise model was ran for 30 epochs with the same parameters as the Tagger model, but an increased hidden dimension size of 650. Some code is provided below to demonstrate the converting of words into their noisy counter part. The result of read_noisy_annotations() is given the the TaggerLSTM as training data.\n",
    "\n",
    "This method lowered the F1 score down to 69.897, so we believe that the model was not implemented as in the paper by Sakaguchi, or that our data was too far skewed to [UNK] and common words within the traning data set.\n",
    "\n",
    "Ouput:\n",
    "Rockwell Internatinal Corp.'s Tulsa unit said it signed a tentative agreement extending its contract with Boeing Co. to provide structural parts for Boeing's 747 jetliners\n",
    "\n",
    "Denoised output:\n",
    "[UNK] International Corp. 's [UNK] unit said it United a little agreement [UNK] its contract with likely Co. to provide structural parts for delivery's,40 [UNK].\n",
    "\n",
    "\n",
    "accuracy:  83.46%; precision:  69.57%; recall:  69.90%; FB1:  69.7\n",
    "\n",
    "             ADJP: precision:  41.46%; recall:  15.04%; FB1:  22.08  82\n",
    "             ADVP: precision:  60.69%; recall:  39.95%; FB1:  48.18  262\n",
    "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
    "               NP: precision:  66.97%; recall:  73.50%; FB1:  70.08  6845\n",
    "               PP: precision:  86.14%; recall:  85.83%; FB1:  85.98  2432\n",
    "              PRT: precision:  66.67%; recall:  53.33%; FB1:  59.26  36\n",
    "             SBAR: precision:  66.39%; recall:  33.33%; FB1:  44.38  119\n",
    "               VP: precision:  61.58%; recall:  58.16%; FB1:  59.82  2176\n",
    "(69.56994645247657, 69.8974445191661, 69.73331096947334)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_noisy_annotations(file):\n",
    "    handle = None\n",
    "    if file[-3:] == '.gz':\n",
    "        handle = gzip.open(file, 'rt')\n",
    "    else:\n",
    "        handle = open(file, 'r')\n",
    "    conll_data = []\n",
    "    contents = re.sub(r'\\n\\s*\\n', r'\\n\\n', handle.read())\n",
    "    contents = contents.rstrip()\n",
    "    for sent_string in contents.split('\\n\\n'):\n",
    "        annotations = list(zip(*[ word_string.split() for word_string in sent_string.split('\\n') ]))\n",
    "        annotations = [[], annotations[0]]\n",
    "        for word in annotations[1]:\n",
    "            annotations[0].append(noise(word))\n",
    "        conll_data.append(( annotations[0], annotations[1] ))\n",
    "        #logging.info(\"CoNLL: {} ||| {}\".format( \" \".join(annotations[0]), \" \".join(annotations[1])))\n",
    "    return conll_data\n",
    "\n",
    "def noise(word):\n",
    "    random.seed(1)\n",
    "#     adding '' empty strings to represent do nothing to word.\n",
    "    choices = ['replace', 'add', 'delete', 'jumble', '', '', '', '', '', '', '']\n",
    "    option = random.choice(choices)\n",
    "    if len(word) > 3 and not hasnum(word) and word != '[UNK]':\n",
    "        if option == 'replace':\n",
    "            pos_replace = random.randint(1, len(word[1:-1]))\n",
    "            rand_char = random.choice(string.ascii_letters.lower())\n",
    "            w = list(word)\n",
    "            w[pos_replace] = rand_char\n",
    "            word = ''.join(w)\n",
    "        elif option == 'add':\n",
    "            pos_add = random.randint(1, len(word[1:-1]))\n",
    "            word = word[:pos_add] + random.choice(string.ascii_lowercase) + word[pos_add:]\n",
    "        elif option == 'delete':\n",
    "            pos_delete = random.randint(1, len(word[1:-1]))\n",
    "            word = word[0: pos_delete:] + word[pos_delete + 1::]\n",
    "        elif option == 'jumble':\n",
    "            shuf_word = ''.join(random.sample(word[1:-1], len(word[1:-1])))\n",
    "            word = word[0] + shuf_word + word[-1]\n",
    "    return word\n",
    "\n",
    "def hasnum(word):\n",
    "    for let in word:\n",
    "        if let.isdigit():\n",
    "            return True\n",
    "    return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python_defaultSpec_1603934777406"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}